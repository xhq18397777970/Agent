import asyncio
import json
import logging
import os
import shutil
import sys
from contextlib import AsyncExitStack
from typing import Any, Dict, List, Optional

import httpx
from dotenv import load_dotenv
from openai import OpenAI  # OpenAI Python SDK
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
 
# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
 
 
# =============================
# é…ç½®åŠ è½½ç±»ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡åŠé…ç½®æ–‡ä»¶ï¼‰
# =============================
# å¯¼å…¥é…ç½®ç®¡ç†å™¨
sys.path.append(os.path.join(os.path.dirname(__file__), 'config'))
from config_manager import get_config_manager

class Configuration:
    """ç®¡ç† MCP å®¢æˆ·ç«¯çš„ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶"""
 
    def __init__(self) -> None:
        self.config_manager = get_config_manager()
        
        # ä»é…ç½®ç®¡ç†å™¨è·å– DeepSeek é…ç½®
        try:
            deepseek_config = self.config_manager.get_deepseek_config()
            self.api_key = deepseek_config["api_key"]
            self.base_url = deepseek_config["base_url"]
            self.model = deepseek_config["model"]
        except ValueError as e:
            raise ValueError(f"âŒ DeepSeek é…ç½®é”™è¯¯: {e}")

    def load_config(self, file_path: str = None) -> Dict[str, Any]:
        """
        ä»é…ç½®ç®¡ç†å™¨åŠ è½½æœåŠ¡å™¨é…ç½®
        
        Args:
            file_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        
        Returns:
            åŒ…å«æœåŠ¡å™¨é…ç½®çš„å­—å…¸
        """
        if file_path:
            # å…¼å®¹æ—§ç‰ˆæœ¬çš„æ–‡ä»¶è·¯å¾„æ–¹å¼
            with open(file_path, "r") as f:
                return json.load(f)
        else:
            # ä½¿ç”¨é…ç½®ç®¡ç†å™¨
            return self.config_manager.load_servers_config()
 
 
# =============================
# MCP æœåŠ¡å™¨å®¢æˆ·ç«¯ç±»
# =============================
class Server:
    """ç®¡ç†å•ä¸ª MCP æœåŠ¡å™¨è¿æ¥å’Œå·¥å…·è°ƒç”¨"""
 
    def __init__(self, name: str, config: Dict[str, Any]) -> None:
        self.name: str = name
        self.config: Dict[str, Any] = config
        self.session: Optional[ClientSession] = None
        self.exit_stack: Optional[AsyncExitStack] = None
        self._cleanup_lock = asyncio.Lock()
        self._initialized = False
 
    async def initialize(self) -> None:
        """åˆå§‹åŒ–ä¸ MCP æœåŠ¡å™¨çš„è¿æ¥"""
        if self._initialized:
            return
            
        # command å­—æ®µç›´æ¥ä»é…ç½®è·å–
        command = self.config["command"]
        if command is None:
            raise ValueError("command ä¸èƒ½ä¸ºç©º")
 
        # åˆ›å»ºæ–°çš„ AsyncExitStack
        self.exit_stack = AsyncExitStack()
        
        server_params = StdioServerParameters(
            command=command,
            args=self.config["args"],
            env={**os.environ, **self.config["env"]} if self.config.get("env") else os.environ,
        )
        try:
            stdio_transport = await self.exit_stack.enter_async_context(
                stdio_client(server_params)
            )
            read_stream, write_stream = stdio_transport
            session = await self.exit_stack.enter_async_context(
                ClientSession(read_stream, write_stream)
            )
            await session.initialize()
            self.session = session
            self._initialized = True
        except Exception as e:
            logging.error(f"Error initializing server {self.name}: {e}")
            await self.cleanup()
            raise
 
    async def list_tools(self) -> List[Any]:
        """è·å–æœåŠ¡å™¨å¯ç”¨çš„å·¥å…·åˆ—è¡¨
        Returns:
            å·¥å…·åˆ—è¡¨
        """
        if not self.session:
            raise RuntimeError(f"Server {self.name} not initialized")
        tools_response = await self.session.list_tools()
        tools = []
        for item in tools_response:
            if isinstance(item, tuple) and item[0] == "tools":
                for tool in item[1]:
                    tools.append(Tool(tool.name, tool.description, tool.inputSchema))
        return tools
 
    async def execute_tool(
        self, tool_name: str, arguments: Dict[str, Any], retries: int = 2, delay: float = 1.0
    ) -> Any:
        """æ‰§è¡ŒæŒ‡å®šå·¥å…·ï¼Œå¹¶æ”¯æŒé‡è¯•æœºåˆ¶
        Args:
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            retries: é‡è¯•æ¬¡æ•°
            delay: é‡è¯•é—´éš”ç§’æ•°
        Returns:
            å·¥å…·è°ƒç”¨ç»“æœ
        """
        if not self.session:
            raise RuntimeError(f"Server {self.name} not initialized")
        attempt = 0
        while attempt < retries:
            try:
                logging.info(f"Executing {tool_name} on server {self.name}...")
                result = await self.session.call_tool(tool_name, arguments)
                return result
            except Exception as e:
                attempt += 1
                logging.warning(
                    f"Error executing tool: {e}. Attempt {attempt} of {retries}."
                )
                if attempt < retries:
                    logging.info(f"Retrying in {delay} seconds...")
                    await asyncio.sleep(delay)
                else:
                    logging.error("Max retries reached. Failing.")
                    raise
 
    async def cleanup(self) -> None:
        """æ¸…ç†æœåŠ¡å™¨èµ„æº"""
        async with self._cleanup_lock:
            if not self._initialized:
                return
                
            # æ ‡è®°ä¸ºæœªåˆå§‹åŒ–çŠ¶æ€ï¼Œé˜²æ­¢é‡å¤æ¸…ç†
            self._initialized = False
            
            try:
                # å…ˆæ¸…ç†session
                if self.session:
                    try:
                        # å°è¯•ä¼˜é›…å…³é—­sessionï¼Œä½†ä¸ç­‰å¾…å¤ªä¹…
                        await asyncio.wait_for(self.session.close(), timeout=0.5)
                    except (asyncio.TimeoutError, AttributeError):
                        # sessionå¯èƒ½æ²¡æœ‰closeæ–¹æ³•æˆ–å·²ç»å…³é—­
                        pass
                    except Exception as e:
                        logging.debug(f"Session cleanup warning for {self.name}: {e}")
                    finally:
                        self.session = None
                    
                # æ¸…ç†exit_stack - ä½¿ç”¨æ›´ä¿å®ˆçš„æ–¹æ³•
                if self.exit_stack:
                    try:
                        # åˆ›å»ºä¸€ä¸ªæ–°çš„ä»»åŠ¡æ¥å¤„ç†æ¸…ç†ï¼Œé¿å…è·¨ä»»åŠ¡èŒƒå›´é—®é¢˜
                        cleanup_task = asyncio.create_task(self._safe_exit_stack_cleanup())
                        await asyncio.wait_for(cleanup_task, timeout=2.0)
                    except asyncio.TimeoutError:
                        logging.info(f"Exit stack cleanup timed out for server {self.name}")
                        cleanup_task.cancel()
                        try:
                            await cleanup_task
                        except asyncio.CancelledError:
                            pass
                    except Exception as e:
                        error_msg = str(e).lower()
                        if any(keyword in error_msg for keyword in ["cancel", "scope", "generatorexit", "different task"]):
                            logging.debug(f"Ignoring expected async cleanup error for server {self.name}: {e}")
                        else:
                            logging.warning(f"Unexpected error during exit_stack cleanup of server {self.name}: {e}")
                    finally:
                        self.exit_stack = None
                        
            except Exception as e:
                error_msg = str(e).lower()
                if any(keyword in error_msg for keyword in ["cancel", "scope", "generatorexit", "different task"]):
                    logging.debug(f"Ignoring expected async cleanup error during server {self.name} cleanup: {e}")
                else:
                    logging.error(f"Unexpected error during cleanup of server {self.name}: {e}")
            finally:
                # ç¡®ä¿çŠ¶æ€è¢«é‡ç½®
                self.session = None
                self.exit_stack = None
                self._initialized = False

    async def _safe_exit_stack_cleanup(self) -> None:
        """å®‰å…¨åœ°æ¸…ç†exit_stackï¼Œåœ¨ç‹¬ç«‹çš„ä»»åŠ¡ä¸­è¿è¡Œ"""
        if self.exit_stack:
            try:
                await self.exit_stack.aclose()
            except Exception as e:
                error_msg = str(e).lower()
                if not any(keyword in error_msg for keyword in ["cancel", "scope", "generatorexit", "different task"]):
                    raise
 
 
# =============================
# å·¥å…·å°è£…ç±»
# =============================
class Tool:
    """å°è£… MCP è¿”å›çš„å·¥å…·ä¿¡æ¯"""
 
    def __init__(self, name: str, description: str, input_schema: Dict[str, Any]) -> None:
        self.name: str = name
        self.description: str = description
        self.input_schema: Dict[str, Any] = input_schema
 
    def format_for_llm(self) -> str:
        """ç”Ÿæˆç”¨äº LLM æç¤ºçš„å·¥å…·æè¿°"""
        args_desc = []
        if "properties" in self.input_schema:
            for param_name, param_info in self.input_schema["properties"].items():
                arg_desc = f"- {param_name}: {param_info.get('description', 'No description')}"
                if param_name in self.input_schema.get("required", []):
                    arg_desc += " (required)"
                args_desc.append(arg_desc)
        return f"""
Tool: {self.name}
Description: {self.description}
Arguments:
{chr(10).join(args_desc)}
"""
 
 
# =============================
# LLM å®¢æˆ·ç«¯å°è£…ç±»ï¼ˆä½¿ç”¨ OpenAI SDKï¼‰
# =============================
class LLMClient:
    """ä½¿ç”¨ OpenAI SDK ä¸å¤§æ¨¡å‹äº¤äº’"""
 
    def __init__(self, api_key: str, base_url: Optional[str], model: str) -> None:
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
 
    def get_response(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None) -> Any:
        """
        å‘é€æ¶ˆæ¯ç»™å¤§æ¨¡å‹ APIï¼Œæ”¯æŒä¼ å…¥å·¥å…·å‚æ•°ï¼ˆfunction calling æ ¼å¼ï¼‰
        """
        payload = {
            "model": self.model,
            "messages": messages,
            "tools": tools,
        }
        try:
            response = self.client.chat.completions.create(**payload)
            return response
        except Exception as e:
            logging.error(f"Error during LLM call: {e}")
            raise
 
 
# =============================
# å¤šæœåŠ¡å™¨ MCP å®¢æˆ·ç«¯ç±»ï¼ˆé›†æˆé…ç½®æ–‡ä»¶ã€å·¥å…·æ ¼å¼è½¬æ¢ä¸ OpenAI SDK è°ƒç”¨ï¼‰
# =============================
class MultiServerMCPClient:
    def __init__(self) -> None:
        """
        ç®¡ç†å¤šä¸ª MCP æœåŠ¡å™¨ï¼Œå¹¶ä½¿ç”¨ OpenAI Function Calling é£æ ¼çš„æ¥å£è°ƒç”¨å¤§æ¨¡å‹
        """
        self.exit_stack = AsyncExitStack()
        config = Configuration()
        self.openai_api_key = config.api_key
        self.base_url = config.base_url
        self.model = config.model
        self.client = LLMClient(self.openai_api_key, self.base_url, self.model)
        # (server_name -> Server å¯¹è±¡)
        self.servers: Dict[str, Server] = {}
        # å„ä¸ª server çš„å·¥å…·åˆ—è¡¨
        self.tools_by_server: Dict[str, List[Any]] = {}
        self.all_tools: List[Dict[str, Any]] = []
 
    async def connect_to_servers(self, servers_config: Dict[str, Any]) -> None:
        """
        æ ¹æ®é…ç½®æ–‡ä»¶åŒæ—¶å¯åŠ¨å¤šä¸ªæœåŠ¡å™¨å¹¶è·å–å·¥å…·
        servers_config çš„æ ¼å¼ä¸ºï¼š
        {
          "mcpServers": {
              "sqlite": { "command": "uvx", "args": [ ... ] },
              "puppeteer": { "command": "npx", "args": [ ... ] },
              ...
          }
        }
        """
        mcp_servers = servers_config.get("mcpServers", {})
        for server_name, srv_config in mcp_servers.items():
            server = Server(server_name, srv_config)
            await server.initialize()
            self.servers[server_name] = server
            tools = await server.list_tools()
            self.tools_by_server[server_name] = tools
 
            for tool in tools:
                # ç»Ÿä¸€é‡å‘½åï¼šserverName_toolName
                function_name = f"{server_name}_{tool.name}"
                self.all_tools.append({
                    "type": "function",
                    "function": {
                        "name": function_name,
                        "description": tool.description,
                        "input_schema": tool.input_schema
                    }
                })
 
        # è½¬æ¢ä¸º OpenAI Function Calling æ‰€éœ€æ ¼å¼
        self.all_tools = await self.transform_json(self.all_tools)
 
        logging.info("\nâœ… å·²è¿æ¥åˆ°ä¸‹åˆ—æœåŠ¡å™¨:")
        for name in self.servers:
            srv_cfg = mcp_servers[name]
            logging.info(f"  - {name}: command={srv_cfg['command']}, args={srv_cfg['args']}")
        logging.info("\næ±‡æ€»çš„å·¥å…·:")
        for t in self.all_tools:
            logging.info(f"  - {t['function']['name']}")
 
    async def transform_json(self, json_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†å·¥å…·çš„ input_schema è½¬æ¢ä¸º OpenAI æ‰€éœ€çš„ parameters æ ¼å¼ï¼Œå¹¶åˆ é™¤å¤šä½™å­—æ®µ
        """
        result = []
        for item in json_data:
            if not isinstance(item, dict) or "type" not in item or "function" not in item:
                continue
            old_func = item["function"]
            if not isinstance(old_func, dict) or "name" not in old_func or "description" not in old_func:
                continue
            new_func = {
                "name": old_func["name"],
                "description": old_func["description"],
                "parameters": {}
            }
            if "input_schema" in old_func and isinstance(old_func["input_schema"], dict):
                old_schema = old_func["input_schema"]
                new_func["parameters"]["type"] = old_schema.get("type", "object")
                new_func["parameters"]["properties"] = old_schema.get("properties", {})
                new_func["parameters"]["required"] = old_schema.get("required", [])
            new_item = {
                "type": item["type"],
                "function": new_func
            }
            result.append(new_item)
        return result
 
    async def chat_base(self, messages: List[Dict[str, Any]]) -> Any:
        """
        ä½¿ç”¨ OpenAI æ¥å£è¿›è¡Œå¯¹è¯ï¼Œå¹¶æ”¯æŒå¤šæ¬¡å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰ã€‚
        å¦‚æœè¿”å› finish_reason ä¸º "tool_calls"ï¼Œåˆ™è¿›è¡Œå·¥å…·è°ƒç”¨åå†å‘èµ·è¯·æ±‚ã€‚
        """
        response = self.client.get_response(messages, tools=self.all_tools)
        # å¦‚æœæ¨¡å‹è¿”å›å·¥å…·è°ƒç”¨
        if response.choices[0].finish_reason == "tool_calls":
            while True:
                messages = await self.create_function_response_messages(messages, response)
                response = self.client.get_response(messages, tools=self.all_tools)
                if response.choices[0].finish_reason != "tool_calls":
                    break
        return response
 
    async def create_function_response_messages(self, messages: List[Dict[str, Any]], response: Any) -> List[Dict[str, Any]]:
        """
        å°†æ¨¡å‹è¿”å›çš„å·¥å…·è°ƒç”¨è§£ææ‰§è¡Œï¼Œå¹¶å°†ç»“æœè¿½åŠ åˆ°æ¶ˆæ¯é˜Ÿåˆ—ä¸­
        """
        function_call_messages = response.choices[0].message.tool_calls
        # ä¿®å¤ï¼šæ­£ç¡®æ ¼å¼åŒ–åŠ©æ‰‹æ¶ˆæ¯
        assistant_message = {
            "role": "assistant",
            "content": response.choices[0].message.content,
            "tool_calls": [
                {
                    "id": tc.id,
                    "type": tc.type,
                    "function": {
                        "name": tc.function.name,
                        "arguments": tc.function.arguments
                    }
                } for tc in function_call_messages
            ]
        }
        messages.append(assistant_message)
        
        for function_call_message in function_call_messages:
            tool_name = function_call_message.function.name
            tool_args = json.loads(function_call_message.function.arguments)
            # è°ƒç”¨ MCP å·¥å…·
            function_response = await self._call_mcp_tool(tool_name, tool_args)
            messages.append({
                "role": "tool",
                "content": str(function_response),  # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²
                "tool_call_id": function_call_message.id,
            })
        return messages
 
    async def process_query(self, user_query: str) -> str:
        """
        OpenAI Function Calling æµç¨‹ï¼š
         1. å‘é€ç”¨æˆ·æ¶ˆæ¯ + å·¥å…·ä¿¡æ¯
         2. è‹¥æ¨¡å‹è¿”å› finish_reason ä¸º "tool_calls"ï¼Œåˆ™è§£æå¹¶è°ƒç”¨ MCP å·¥å…·
         3. å°†å·¥å…·è°ƒç”¨ç»“æœè¿”å›ç»™æ¨¡å‹ï¼Œè·å¾—æœ€ç»ˆå›ç­”
        """
        messages = [{"role": "user", "content": user_query}]
        response = self.client.get_response(messages, tools=self.all_tools)
        content = response.choices[0]
        logging.info(content)
        if content.finish_reason == "tool_calls":
            tool_call = content.message.tool_calls[0]
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)
            logging.info(f"\n[ è°ƒç”¨å·¥å…·: {tool_name}, å‚æ•°: {tool_args} ]\n")
            result = await self._call_mcp_tool(tool_name, tool_args)
            
            # ä¿®å¤ï¼šæ­£ç¡®æ ¼å¼åŒ–åŠ©æ‰‹æ¶ˆæ¯
            assistant_message = {
                "role": "assistant",
                "content": content.message.content,
                "tool_calls": [
                    {
                        "id": tool_call.id,
                        "type": tool_call.type,
                        "function": {
                            "name": tool_call.function.name,
                            "arguments": tool_call.function.arguments
                        }
                    }
                ]
            }
            messages.append(assistant_message)
            messages.append({
                "role": "tool",
                "content": str(result),  # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²
                "tool_call_id": tool_call.id,
            })
            response = self.client.get_response(messages, tools=self.all_tools)
            return response.choices[0].message.content
        return content.message.content
 
    async def _call_mcp_tool(self, tool_full_name: str, tool_args: Dict[str, Any]) -> str:
        """
        æ ¹æ® "serverName_toolName" æ ¼å¼è°ƒç”¨ç›¸åº” MCP å·¥å…·
        """
        parts = tool_full_name.split("_", 1)
        if len(parts) != 2:
            return f"æ— æ•ˆçš„å·¥å…·åç§°: {tool_full_name}"
        server_name, tool_name = parts
        server = self.servers.get(server_name)
        if not server:
            return f"æ‰¾ä¸åˆ°æœåŠ¡å™¨: {server_name}"
        resp = await server.execute_tool(tool_name, tool_args)
        return resp.content if resp.content else "å·¥å…·æ‰§è¡Œæ— è¾“å‡º"
 
    async def chat_loop(self) -> None:
        """å¤šæœåŠ¡å™¨ MCP + OpenAI Function Calling å®¢æˆ·ç«¯ä¸»å¾ªç¯"""
        logging.info("\nğŸ¤– å¤šæœåŠ¡å™¨ MCP + Function Calling å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡ºã€‚")
        messages: List[Dict[str, Any]] = []
        while True:
            query = input("\nä½ : ").strip()
            if query.lower() == "quit":
                break
            try:
                messages.append({"role": "user", "content": query})
                messages = messages[-20:]  # ä¿æŒæœ€æ–° 20 æ¡ä¸Šä¸‹æ–‡
                response = await self.chat_base(messages)
                messages.append(response.choices[0].message.model_dump())
                result = response.choices[0].message.content
                # logging.info(f"\nAI: {result}")
                print(f"\nAI: {result}")
            except Exception as e:
                print(f"\nâš ï¸  è°ƒç”¨è¿‡ç¨‹å‡ºé”™: {e}")
 
    async def cleanup(self) -> None:
        """å…³é—­æ‰€æœ‰èµ„æº"""
        logging.info("å¼€å§‹æ¸…ç†MCPå®¢æˆ·ç«¯èµ„æº...")
        
        # é¦–å…ˆæ¸…ç†æ‰€æœ‰æœåŠ¡å™¨ï¼Œä½¿ç”¨å¹¶å‘ä½†æœ‰é™åˆ¶çš„æ–¹å¼
        cleanup_tasks = []
        for server_name, server in list(self.servers.items()):
            task = asyncio.create_task(self._cleanup_single_server(server_name, server))
            cleanup_tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰æœåŠ¡å™¨æ¸…ç†å®Œæˆï¼Œä½†è®¾ç½®æ€»ä½“è¶…æ—¶
        if cleanup_tasks:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*cleanup_tasks, return_exceptions=True),
                    timeout=5.0
                )
            except asyncio.TimeoutError:
                logging.info("æœåŠ¡å™¨æ¸…ç†è¶…æ—¶ï¼Œå–æ¶ˆå‰©ä½™ä»»åŠ¡")
                for task in cleanup_tasks:
                    if not task.done():
                        task.cancel()
                # ç­‰å¾…å–æ¶ˆå®Œæˆ
                await asyncio.gather(*cleanup_tasks, return_exceptions=True)
        
        # æ¸…ç†ä¸»è¦çš„ exit_stack - ä½¿ç”¨ç‹¬ç«‹ä»»åŠ¡é¿å…è·¨ä»»åŠ¡èŒƒå›´é—®é¢˜
        if hasattr(self, 'exit_stack') and self.exit_stack:
            try:
                cleanup_task = asyncio.create_task(self._safe_main_exit_stack_cleanup())
                await asyncio.wait_for(cleanup_task, timeout=2.0)
            except asyncio.TimeoutError:
                logging.info("ä¸»exit_stackæ¸…ç†è¶…æ—¶")
                cleanup_task.cancel()
                try:
                    await cleanup_task
                except asyncio.CancelledError:
                    pass
            except Exception as e:
                error_msg = str(e).lower()
                if any(keyword in error_msg for keyword in ["cancel", "scope", "generatorexit", "different task"]):
                    logging.debug(f"å¿½ç•¥é¢„æœŸçš„ä¸»æ¸…ç†å¼‚å¸¸: {e}")
                else:
                    logging.warning(f"ä¸»æ¸…ç†è¿‡ç¨‹ä¸­çš„æ„å¤–é”™è¯¯: {e}")
        
        # æ¸…ç†çŠ¶æ€
        self.servers.clear()
        self.tools_by_server.clear()
        self.all_tools.clear()
        logging.info("MCPå®¢æˆ·ç«¯èµ„æºæ¸…ç†å®Œæˆ")

    async def _cleanup_single_server(self, server_name: str, server) -> None:
        """æ¸…ç†å•ä¸ªæœåŠ¡å™¨"""
        try:
            logging.info(f"æ­£åœ¨æ¸…ç†æœåŠ¡å™¨: {server_name}")
            await asyncio.wait_for(server.cleanup(), timeout=3.0)
            logging.debug(f"æœåŠ¡å™¨ {server_name} æ¸…ç†æˆåŠŸ")
        except asyncio.TimeoutError:
            logging.info(f"æœåŠ¡å™¨ {server_name} æ¸…ç†è¶…æ—¶")
        except Exception as e:
            error_msg = str(e).lower()
            if any(keyword in error_msg for keyword in ["cancel", "scope", "generatorexit", "subprocess", "different task"]):
                logging.debug(f"å¿½ç•¥æœåŠ¡å™¨ {server_name} çš„é¢„æœŸæ¸…ç†å¼‚å¸¸: {e}")
            else:
                logging.warning(f"æ¸…ç†æœåŠ¡å™¨ {server_name} æ—¶å‡ºé”™: {e}")

    async def _safe_main_exit_stack_cleanup(self) -> None:
        """å®‰å…¨åœ°æ¸…ç†ä¸»exit_stack"""
        if hasattr(self, 'exit_stack') and self.exit_stack:
            try:
                await self.exit_stack.aclose()
            except Exception as e:
                error_msg = str(e).lower()
                if not any(keyword in error_msg for keyword in ["cancel", "scope", "generatorexit", "different task"]):
                    raise
 
 
# =============================
# ä¸»å‡½æ•°
# =============================
async def main() -> None:
    """ä¸»å‡½æ•° - æ”¹è¿›çš„å¼‚å¸¸å¤„ç†å’Œèµ„æºæ¸…ç†"""
    client = None
    
    try:
        # ä½¿ç”¨é…ç½®ç®¡ç†å™¨åŠ è½½æœåŠ¡å™¨é…ç½®
        config = Configuration()
        servers_config = config.load_config()  # ä½¿ç”¨é…ç½®ç®¡ç†å™¨
        client = MultiServerMCPClient()
        
        # è¿æ¥æœåŠ¡å™¨
        await client.connect_to_servers(servers_config)
        
        # å¼€å§‹èŠå¤©å¾ªç¯
        await client.chat_loop()
        
    except KeyboardInterrupt:
        logging.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º...")
    except Exception as e:
        logging.error(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        logging.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
    finally:
        # èµ„æºæ¸…ç† - ä½¿ç”¨æ›´å¥å£®çš„æ–¹æ³•
        if client is not None:
            logging.info("æ­£åœ¨æ¸…ç†èµ„æº...")
            
            # åˆ›å»ºä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯ä»»åŠ¡æ¥å¤„ç†æ¸…ç†ï¼Œé¿å…è·¨ä»»åŠ¡é—®é¢˜
            cleanup_task = None
            try:
                # ç»™æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ä¸€ç‚¹æ—¶é—´å®Œæˆ
                await asyncio.sleep(0.1)
                
                # åˆ›å»ºæ¸…ç†ä»»åŠ¡
                cleanup_task = asyncio.create_task(client.cleanup())
                
                # ç­‰å¾…æ¸…ç†å®Œæˆï¼Œè®¾ç½®åˆç†çš„è¶…æ—¶
                await asyncio.wait_for(cleanup_task, timeout=8.0)
                logging.info("èµ„æºæ¸…ç†å®Œæˆ")
                
            except asyncio.TimeoutError:
                logging.info("èµ„æºæ¸…ç†è¶…æ—¶ï¼Œæ­£åœ¨å¼ºåˆ¶æ¸…ç†...")
                if cleanup_task and not cleanup_task.done():
                    cleanup_task.cancel()
                    try:
                        await cleanup_task
                    except asyncio.CancelledError:
                        logging.info("æ¸…ç†ä»»åŠ¡å·²å–æ¶ˆ")
                        
            except Exception as e:
                # å¤„ç†å„ç§å¯èƒ½çš„æ¸…ç†å¼‚å¸¸
                error_msg = str(e).lower()
                expected_errors = [
                    "cancel", "scope", "generatorexit", "subprocess",
                    "wait", "different task", "runtimeerror"
                ]
                
                if any(keyword in error_msg for keyword in expected_errors):
                    logging.debug(f"é€€å‡ºæ—¶æ£€æµ‹åˆ°é¢„æœŸçš„å¼‚æ­¥æ¸…ç†å¼‚å¸¸ï¼ˆå·²å¿½ç•¥ï¼‰: {e}")
                else:
                    logging.warning(f"æ¸…ç†èµ„æºæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
            
            # æœ€ç»ˆçŠ¶æ€æ¸…ç†
            try:
                # ç»™ç³»ç»Ÿä¸€ç‚¹æ—¶é—´å®Œæˆæœ€åçš„æ¸…ç†
                await asyncio.sleep(0.05)
            except:
                pass
                
        logging.info("ç¨‹åºé€€å‡º")


def run_main():
    """è¿è¡Œä¸»å‡½æ•°çš„åŒ…è£…å™¨ï¼Œå¤„ç†äº‹ä»¶å¾ªç¯ç›¸å…³çš„å¼‚å¸¸"""
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logging.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        error_msg = str(e).lower()
        expected_errors = [
            "cancel", "scope", "generatorexit", "runtimeerror",
            "attempted to exit cancel scope", "different task"
        ]
        
        if any(keyword in error_msg for keyword in expected_errors):
            logging.debug(f"ç¨‹åºé€€å‡ºæ—¶çš„é¢„æœŸå¼‚å¸¸ï¼ˆå·²å¿½ç•¥ï¼‰: {e}")
        else:
            logging.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")


if __name__ == "__main__":
    run_main()